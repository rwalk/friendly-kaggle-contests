{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#\n",
    "#  EXPEDIA HOTEL CONTEST 2016\n",
    "#\n",
    "Column name\tDescription\tData type\n",
    "date_time \tTimestamp \tstring\n",
    "site_name \tID of the Expedia point of sale (i.e. Expedia.com, Expedia.co.uk, Expedia.co.jp, ...) \tint\n",
    "posa_continent \tID of continent associated with site_name \tint\n",
    "user_location_country \tThe ID of the country the customer is located \tint\n",
    "user_location_region \tThe ID of the region the customer is located \tint\n",
    "user_location_city \tThe ID of the city the customer is located \tint\n",
    "orig_destination_distance \tPhysical distance between a hotel and a customer at the time of search. A null means the distance could not be calculated \tdouble\n",
    "user_id \tID of user \tint\n",
    "is_mobile \t1 when a user connected from a mobile device, 0 otherwise \ttinyint\n",
    "is_package \t1 if the click/booking was generated as a part of a package (i.e. combined with a flight), 0 otherwise \tint\n",
    "channel \tID of a marketing channel \tint\n",
    "srch_ci \tCheckin date \tstring\n",
    "srch_co \tCheckout date \tstring\n",
    "srch_adults_cnt \tThe number of adults specified in the hotel room \tint\n",
    "srch_children_cnt \tThe number of (extra occupancy) children specified in the hotel room \tint\n",
    "srch_rm_cnt \tThe number of hotel rooms specified in the search \tint\n",
    "srch_destination_id \tID of the destination where the hotel search was performed \tint\n",
    "srch_destination_type_id \tType of destination \tint\n",
    "hotel_continent \tHotel continent \tint\n",
    "hotel_country \tHotel country \tint\n",
    "hotel_market \tHotel market \tint\n",
    "is_booking \t1 if a booking, 0 if a click \ttinyint\n",
    "cnt \tNumer of similar events in the context of the same user session \tbigint\n",
    "hotel_cluster \tID of a hotel cluster \tint\n",
    "\n",
    "destinations.csv\n",
    "Column name\tDescription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#\n",
    "# SAMPLE RANDOMLY AND SPLIT TRAINING DATA\n",
    "#\n",
    "import random\n",
    "import csv\n",
    "\n",
    "def split_file(fname, N):\n",
    "    # open a N files named like fname but with a .i.csv suffix\n",
    "    files = [csv.writer(open(fname + \".%d.csv\" % i, \"w\")) for i in range(1,N+1)]\n",
    "    try:\n",
    "        with open(fname) as f:\n",
    "            reader = csv.reader(f)\n",
    "            header = next(reader)\n",
    "            index = dict((key,index) for index,key in enumerate(header))\n",
    "            for file in files:\n",
    "                file.writerow(header)\n",
    "            for row in reader:\n",
    "                if row[index[\"is_booking\"]]==\"1\":\n",
    "                    pick = random.choice(files)\n",
    "                    pick.writerow(row)\n",
    "    finally:\n",
    "        for file in files:\n",
    "            file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import ml_metrics as metrics\n",
    "import pickle\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from datetime import datetime\n",
    "\n",
    "# Helper functions\n",
    "DATE_FORMAT = \"%Y-%m-%d\"\n",
    "\n",
    "def get_trip_duration(checkin, checkout):\n",
    "    if len(checkin)>0 and len(checkout)>0:\n",
    "        a = datetime.strptime(checkin, DATE_FORMAT)\n",
    "        b = datetime.strptime(checkout, DATE_FORMAT)\n",
    "        delta = b - a\n",
    "        return delta.days\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "# a scoring function\n",
    "def score(actual, predicted, k):\n",
    "    return metrics.mapk(actual, predicted, k)\n",
    "\n",
    "# TODO: Merge the subsampling with the read/parse step\n",
    "def subsample(X,y, value_list):\n",
    "    Xsub, ysub = [],[]\n",
    "    counts = dict((k,0) for k in value_list)\n",
    "    i = 0\n",
    "    while i<len(X) and len(value_list)>0:\n",
    "        label, row = y[i], X[i]\n",
    "        i+=1\n",
    "        if counts[label]<5000:\n",
    "            ysub.append(label)\n",
    "            Xsub.append(row)\n",
    "            counts[label]+=1\n",
    "        if label in value_list and counts[label]==5000:\n",
    "            value_list.remove(label)\n",
    "    return Xsub, ysub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of raw data: 3000693 x 7\n",
      "Size of downsampled data: 495148 x 7\n",
      "Size of encoded data: 495148 x 23554\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# read in and parse the data\n",
    "#\n",
    "X,y = [],[]\n",
    "with open(\"./data/train.csv\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    header = next(reader)\n",
    "    \n",
    "    # build map from name -> index\n",
    "    index = dict((key,index) for index,key in enumerate(header))\n",
    "    \n",
    "    # map records into an array.  Arrange so that categoricial variables appear first in each row.\n",
    "    for row in reader:\n",
    "        if row[index[\"is_booking\"]]==\"1\":\n",
    "            y.append(int(row[index[\"hotel_cluster\"]]))\n",
    "            xrow = [int(row[index[\"srch_destination_id\"]]),\n",
    "                    int(row[index[\"hotel_market\"]]),\n",
    "                    int(row[index[\"hotel_country\"]]),\n",
    "                    int(row[index[\"channel\"]]),\n",
    "                    int(row[index[\"is_package\"]]),\n",
    "                    int(row[index[\"srch_adults_cnt\"]]) + int(row[index[\"srch_children_cnt\"]]), \n",
    "                    int(row[index[\"srch_rm_cnt\"]])]\n",
    "            X.append(xrow)\n",
    "    NUMBER_CATEGORICAL = 7\n",
    "\n",
    "print(\"Size of raw data: %d x %d\" % (len(X),len(X[0])))\n",
    "\n",
    "# downsample\n",
    "X, y = subsample(X, y, set(y))\n",
    "print(\"Size of downsampled data: %d x %d\" % (len(X),len(X[0])))\n",
    "\n",
    "# one-hot encoder breaks categorical variables into binary features for each value \n",
    "encoder = OneHotEncoder(categorical_features=[i for i in range(0, 6)])\n",
    "X_onehot = encoder.fit_transform(X)\n",
    "print(\"Size of encoded data: %d x %d\" % X_onehot.shape)\n",
    "\n",
    "# Split the data into train and test.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_onehot, y, test_size=0.25)\n",
    "print(\"Size of training data: %d x %d\" % X_train.shape)\n",
    "print(\"Size of test data: %d x %d\" % X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.01009, std: 0.00010, params: {'alpha': 0.1, 'penalty': 'l1'}\n",
      "mean: 0.08999, std: 0.00086, params: {'alpha': 0.1, 'penalty': 'l2'}\n",
      "mean: 0.01913, std: 0.00203, params: {'alpha': 0.01, 'penalty': 'l1'}\n",
      "mean: 0.10038, std: 0.00078, params: {'alpha': 0.01, 'penalty': 'l2'}\n",
      "mean: 0.07934, std: 0.00155, params: {'alpha': 0.001, 'penalty': 'l1'}\n",
      "mean: 0.12760, std: 0.00109, params: {'alpha': 0.001, 'penalty': 'l2'}\n",
      "mean: 0.13835, std: 0.00113, params: {'alpha': 0.0001, 'penalty': 'l1'}\n",
      "mean: 0.16857, std: 0.00015, params: {'alpha': 0.0001, 'penalty': 'l2'}\n",
      "mean: 0.18379, std: 0.00101, params: {'alpha': 1e-05, 'penalty': 'l1'}\n",
      "mean: 0.18425, std: 0.00171, params: {'alpha': 1e-05, 'penalty': 'l2'}\n",
      "mean: 0.16026, std: 0.00454, params: {'alpha': 1e-06, 'penalty': 'l1'}\n",
      "mean: 0.14691, std: 0.00561, params: {'alpha': 1e-06, 'penalty': 'l2'}\n",
      "SCORE SGD MODEL with k=1 : 0.187628749384\n",
      "SCORE SGD MODEL with k=2 : 0.244751064328\n",
      "SCORE SGD MODEL with k=3 : 0.273803657358\n",
      "SCORE SGD MODEL with k=4 : 0.291244907247\n",
      "SCORE SGD MODEL with k=5 : 0.302609590129\n"
     ]
    }
   ],
   "source": [
    "# fit SGD model:\n",
    "# SGD has a tunable parameter called \"alpha\" which will affect how the model performs\n",
    "# We should cross-validation to find the best value of \"alpha\"\n",
    "#\n",
    "sgd_model = SGDClassifier(loss=\"log\", penalty=\"l1\", n_jobs=-1)\n",
    "parameters = { 'penalty':(\"l1\", \"l2\"), 'alpha': [10.0**(-i) for i in range(1,7)] }\n",
    "\n",
    "# grid search\n",
    "best_sgd = GridSearchCV(sgd_model, parameters, cv=4)\n",
    "best_sgd.fit(X_train, y_train)\n",
    "for report in best_sgd.grid_scores_:\n",
    "    print(report)\n",
    "\n",
    "# test performance on the test data with various score regimes.\n",
    "y_values = sorted(list(set(y)))\n",
    "for i in range(1,6):\n",
    "    y_predicted = [sorted(y_values, key=lambda i: row[i], reverse=True)[:i] for row in best_sgd.predict_proba(X_test)]\n",
    "    print(\"SCORE SGD MODEL with k=%d : %s\" % (i, score([[a] for a in y_test], y_predicted, i)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
