{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Solution for Kaggle contest problem -> https://www.kaggle.com/c/expedia-hotel-recommendations\n",
    "create a \"data\" directory in same level as this file, with contens from this location ->\n",
    "https://www.kaggle.com/c/expedia-hotel-recommendations/data\n",
    "\"\"\"\n",
    "import csv\n",
    "import ml_metrics as metrics\n",
    "import pickle\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from datetime import datetime\n",
    "\n",
    "DATE_FORMAT = \"%Y-%m-%d\"\n",
    "\n",
    "def get_trip_duration(checkin, checkout):\n",
    "    if len(checkin)>0 and len(checkout)>0:\n",
    "        a = datetime.strptime(checkin, DATE_FORMAT)\n",
    "        b = datetime.strptime(checkout, DATE_FORMAT)\n",
    "        delta = b - a\n",
    "        return delta.days\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# a scoring function\n",
    "def score(actual, predicted, k):\n",
    "    return metrics.mapk(actual, predicted, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# read in and parse the data\n",
    "X,y = [],[]\n",
    "\n",
    "import os.path\n",
    "\n",
    "# load pickle data if exists\n",
    "if os.path.isfile(\"./data/X.pickle\") and os.path.isfile(\"./data/y.pickle\"):\n",
    "    print('using pickle files')\n",
    "    with open(\"./data/X.pickle\", \"rb\") as f:\n",
    "        X = pickle.load(f)\n",
    "    with open(\"./data/Y.pickle\", \"rb\") as f:\n",
    "        y = pickle.load(f)\n",
    "else:\n",
    "    with open(\"./data/train.csv\") as f:\n",
    "        reader = csv.reader(f)\n",
    "        header = next(reader)\n",
    "        index = dict((key,index) for index,key in enumerate(header))\n",
    "        for row in reader:\n",
    "            if row[-1] !=0:\n",
    "                #row = dict((k,v) for k,v in zip(header, r))\n",
    "                y.append(int(row[index[\"hotel_cluster\"]]))\n",
    "                xrow = [int(row[index[\"srch_destination_type_id\"]]),\n",
    "                        int(row[index[\"site_name\"]]),\n",
    "                        int(row[index[\"hotel_market\"]]),\n",
    "                        int(row[index[\"channel\"]]),\n",
    "                        int(row[index[\"is_mobile\"]]), \n",
    "                        int(row[index[\"is_package\"]]),\n",
    "                        int(row[index[\"srch_adults_cnt\"]]),\n",
    "                        int(row[index[\"srch_children_cnt\"]]), \n",
    "                        int(row[index[\"srch_rm_cnt\"]]),\n",
    "                        get_trip_duration(row[index['srch_ci']], row[index['srch_co']]),\n",
    "                        int(row[index[\"cnt\"]])]\n",
    "                X.append(xrow)\n",
    "                \n",
    "    # this stuff is a pain to load in; let's pickle it so we can pull it back more quickly next time!\n",
    "    with open(\"./data/X.pickle\", \"wb\") as f:\n",
    "        pickle.dump(X, f)\n",
    "    with open(\"./data/Y.pickle\", \"wb\") as f:\n",
    "        pickle.dump(y, f)\n",
    "        \n",
    "print(\"Size of raw data X: %d x %d\" % (len(X),len(X[0])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# the data is just too big to do much with.  We need to subsample and try to get equal numbers of each class represented.\n",
    "# TODO: Merge the subsampling with the read/parse step\n",
    "def subsample(X,y, value_list):\n",
    "    Xsub, ysub = [],[]\n",
    "    counts = dict((k,0) for k in value_list)\n",
    "    i = 0\n",
    "    while i<len(X) and len(value_list)>0:\n",
    "        label, row = y[i], X[i]\n",
    "        i+=1\n",
    "        if counts[label]<5000:\n",
    "            ysub.append(label)\n",
    "            Xsub.append(row)\n",
    "            counts[label]+=1\n",
    "        if label in value_list and counts[label]==5000:\n",
    "            value_list.remove(label)\n",
    "    return Xsub, ysub\n",
    "\n",
    "# subsample\n",
    "X, y = subsample(X,y, set(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# one-hot encoder breaks categorical variables into binary features for each value \n",
    "encoder = OneHotEncoder(categorical_features=[0,1,2,3])\n",
    "X_onehot = encoder.fit_transform(X)\n",
    "print(\"Size of encoded data: %d x %d\" % X_onehot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Split the data into train and test.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_onehot, y, test_size=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "# fit SGD model:\n",
    "# SGD has a tunable parameter called \"alpha\" which will affect how the model performs\n",
    "# We should cross-validation to find the best value of \"alpha\"\n",
    "#\n",
    "\n",
    "sgd_model = SGDClassifier(loss=\"log\", penalty=\"l1\", n_jobs=-1)\n",
    "parameters = { 'alpha': [10.0**(-i) for i in range(1,7)] }\n",
    "\n",
    "# grid search\n",
    "best_sgd = GridSearchCV(sgd_model, parameters, cv=4)\n",
    "best_sgd.fit(X_train, y_train)\n",
    "for report in best_sgd.grid_scores_:\n",
    "    print(report)\n",
    "\n",
    "# call to predict will use the \"best\" estimator found by CV\n",
    "y_predicted = best_sgd.predict(X_test)\n",
    "print(\"SCORE SGD MODEL: %s\" % score([[a] for a in y_test], X, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# fit SGD model and predict with scoring for one value\n",
    "sgd_model = SGDClassifier(loss=\"log\", penalty=\"l1\", n_jobs=-1, alpha=.00001)\n",
    "sgd_model.fit(X_train, y_train)\n",
    "y_predicted = sgd_model.predict(X_test)\n",
    "print(\"SCORE SGD MODEL: %s\" % score([[a] for a in y_test], [[p] for p in y_predicted.tolist()], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# choose the top 5 best categories for each prediction\n",
    "y_values = sorted(list(set(y)))\n",
    "y_predicted = [sorted(y_values, key=lambda i: row[i], reverse=True)[:5] for row in sgd_model.predict_proba(X_test)]\n",
    "#print(y_predicted)\n",
    "print(\"SCORE SGD MODEL: %s\" % score([[a] for a in y_test], [p for p in y_predicted], 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# fit the logistic regression model -- careful it might take a while to fit this\n",
    "sgd_model = LogisticRegression(n_jobs=-1)\n",
    "sgd_model.fit(X_train, y_train)\n",
    "y_predicted = sgd_model.predict(X_test)\n",
    "print(\"SCORE LOGISTIC REGRESSION MODEL: %s\" % score([[a] for a in y_test], [[p] for p in y_predicted.tolist()], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
